{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9990717,"sourceType":"datasetVersion","datasetId":6137998}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\n\n\nclass Window:\n\n    def __init__(self, window_min, window_max):\n        self.window_min = window_min\n        self.window_max = window_max\n\n    def __call__(self, image):\n        image = np.clip(image, self.window_min, self.window_max)\n\n        return image\n\n\nclass MinMaxNorm:\n\n    def __init__(self, low, high):\n        self.low = low\n        self.high = high\n\n    def __call__(self, image):\n        image = (image - self.low) / (self.high - self.low)\n        image = image * 2 - 1\n\n        return image","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom itertools import product\n\nimport nibabel as nib\nimport numpy as np\nimport torch\nfrom skimage.measure import regionprops\nfrom torch.utils.data import DataLoader, Dataset\n\n\nclass FracNetTrainDataset(Dataset):\n\n    def __init__(self, image_dir, label_dir=None, crop_size=64,\n            transforms=None, num_samples=4, train=True):\n        self.image_dir = image_dir\n        self.label_dir = label_dir\n        self.public_id_list = sorted([x.split(\"-\")[0]\n            for x in os.listdir(image_dir)])\n        self.crop_size = crop_size\n        self.transforms = transforms\n        self.num_samples = num_samples\n        self.train = train\n\n    def __len__(self):\n        return len(self.public_id_list)\n\n    @staticmethod\n    def _get_pos_centroids(label_arr):\n        centroids = [tuple([round(x) for x in prop.centroid])\n            for prop in regionprops(label_arr)]\n\n        return centroids\n\n    @staticmethod\n    def _get_symmetric_neg_centroids(pos_centroids, x_size):\n        sym_neg_centroids = [(x_size - x, y, z) for x, y, z in pos_centroids]\n\n        return sym_neg_centroids\n\n    @staticmethod\n    def _get_spine_neg_centroids(shape, crop_size, num_samples):\n        x_min, x_max = shape[0] // 2 - 40, shape[0] // 2 + 40\n        y_min, y_max = 300, 400\n        z_min, z_max = crop_size // 2, shape[2] - crop_size // 2\n        spine_neg_centroids = [(\n            np.random.randint(x_min, x_max),\n            np.random.randint(y_min, y_max),\n            np.random.randint(z_min, z_max)\n        ) for _ in range(num_samples)]\n\n        return spine_neg_centroids\n\n    def _get_neg_centroids(self, pos_centroids, image_shape):\n        num_pos = len(pos_centroids)\n        sym_neg_centroids = self._get_symmetric_neg_centroids(\n            pos_centroids, image_shape[0])\n\n        if num_pos < self.num_samples // 2:\n            spine_neg_centroids = self._get_spine_neg_centroids(image_shape,\n                self.crop_size, self.num_samples - 2 * num_pos)\n        else:\n            spine_neg_centroids = self._get_spine_neg_centroids(image_shape,\n                self.crop_size, num_pos)\n\n        return sym_neg_centroids + spine_neg_centroids\n\n    def _get_roi_centroids(self, label_arr):\n        if self.train:\n            # generate positive samples' centroids\n            pos_centroids = self._get_pos_centroids(label_arr)\n\n            # generate negative samples' centroids\n            neg_centroids = self._get_neg_centroids(pos_centroids,\n                label_arr.shape)\n\n            # sample positives and negatives when necessary\n            num_pos = len(pos_centroids)\n            num_neg = len(neg_centroids)\n            if num_pos >= self.num_samples:\n                num_pos = self.num_samples // 2\n                num_neg = self.num_samples // 2\n            elif num_pos >= self.num_samples // 2:\n                num_neg = self.num_samples - num_pos\n\n            if num_pos < len(pos_centroids):\n                pos_centroids = [pos_centroids[i] for i in np.random.choice(\n                    range(0, len(pos_centroids)), size=num_pos, replace=False)]\n            if num_neg < len(neg_centroids):\n                neg_centroids = [neg_centroids[i] for i in np.random.choice(\n                    range(0, len(neg_centroids)), size=num_neg, replace=False)]\n\n            roi_centroids = pos_centroids + neg_centroids\n        else:\n            roi_centroids = [list(range(0, x, y // 2))[1:-1] + [x - y // 2]\n                for x, y in zip(label_arr.shape, self.crop_size)]\n            roi_centroids = list(product(*roi_centroids))\n\n        roi_centroids = [tuple([int(x) for x in centroid])\n            for centroid in roi_centroids]\n\n        return roi_centroids\n\n    def _crop_roi(self, arr, centroid):\n        roi = np.ones(tuple([self.crop_size] * 3)) * (-1024)\n\n        src_beg = [max(0, centroid[i] - self.crop_size // 2)\n            for i in range(len(centroid))]\n        src_end = [min(arr.shape[i], centroid[i] + self.crop_size // 2)\n            for i in range(len(centroid))]\n        dst_beg = [max(0, self.crop_size // 2 - centroid[i])\n            for i in range(len(centroid))]\n        dst_end = [min(arr.shape[i] - (centroid[i] - self.crop_size // 2),\n            self.crop_size) for i in range(len(centroid))]\n        roi[\n            dst_beg[0]:dst_end[0],\n            dst_beg[1]:dst_end[1],\n            dst_beg[2]:dst_end[2],\n        ] = arr[\n            src_beg[0]:src_end[0],\n            src_beg[1]:src_end[1],\n            src_beg[2]:src_end[2],\n        ]\n\n        return roi\n\n    def _apply_transforms(self, image):\n        for t in self.transforms:\n            image = t(image)\n\n        return image\n\n    def __getitem__(self, idx):\n        # read image and label\n        public_id = self.public_id_list[idx]\n        image_path = os.path.join(self.image_dir, f\"{public_id}-image.nii\")\n        label_path = os.path.join(self.label_dir, f\"{public_id}-label.nii\")\n        image = nib.load(image_path)\n        label = nib.load(label_path)\n        image_arr = image.get_fdata().astype(float)\n        label_arr = label.get_fdata().astype(np.uint8)\n\n        # calculate rois' centroids\n        roi_centroids = self._get_roi_centroids(label_arr)\n\n        # crop rois\n        image_rois = [self._crop_roi(image_arr, centroid)\n            for centroid in roi_centroids]\n        label_rois = [self._crop_roi(label_arr, centroid)\n            for centroid in roi_centroids]\n\n        if self.transforms is not None:\n            image_rois = [self._apply_transforms(image_roi)\n                for image_roi in image_rois]\n\n        image_rois = torch.tensor(np.stack(image_rois)[:, np.newaxis],\n            dtype=torch.float)\n        label_rois = (np.stack(label_rois) > 0).astype(float)\n        label_rois = torch.tensor(label_rois[:, np.newaxis],\n            dtype=torch.float)\n        label_rois =label_rois.squeeze()\n        return image_rois, label_rois\n\n    @staticmethod\n    def collate_fn(samples):\n        image_rois = torch.cat([x[0] for x in samples])\n        label_rois = torch.cat([x[1] for x in samples])\n\n        return image_rois, label_rois\n\n    @staticmethod\n    def get_dataloader(dataset, batch_size, shuffle=False, num_workers=0):\n        return DataLoader(dataset=dataset, batch_size=batch_size, shuffle=shuffle,\n            num_workers=num_workers, collate_fn=FracNetTrainDataset.collate_fn)\n\n\nclass FracNetInferenceDataset(Dataset):\n\n    def __init__(self, image_path, crop_size=64, transforms=None):\n        image = nib.load(image_path)\n        self.image_affine = image.affine\n        self.image = image.get_fdata().astype(np.int16)\n        self.crop_size = crop_size\n        self.transforms = transforms\n        self.centers = self._get_centers()\n\n    def _get_centers(self):\n        dim_coords = [list(range(0, dim, self.crop_size // 2))[1:-1]\\\n            + [dim - self.crop_size // 2] for dim in self.image.shape]\n        centers = list(product(*dim_coords))\n\n        return centers\n\n    def __len__(self):\n        return len(self.centers)\n\n    def _crop_patch(self, idx):\n        center_x, center_y, center_z = self.centers[idx]\n        patch = self.image[\n            center_x - self.crop_size // 2:center_x + self.crop_size // 2,\n            center_y - self.crop_size // 2:center_y + self.crop_size // 2,\n            center_z - self.crop_size // 2:center_z + self.crop_size // 2\n        ]\n\n        return patch\n\n    def _apply_transforms(self, image):\n        for t in self.transforms:\n            image = t(image)\n\n        return image\n\n    def __getitem__(self, idx):\n        image = self._crop_patch(idx)\n        center = self.centers[idx]\n\n        if self.transforms is not None:\n            image = self._apply_transforms(image)\n\n        image = torch.tensor(image[np.newaxis], dtype=torch.float)\n\n        return image, center\n\n    @staticmethod\n    def _collate_fn(samples):\n        images = torch.stack([x[0] for x in samples])\n        centers = [x[1] for x in samples]\n\n        return images, centers\n\n    @staticmethod\n    def get_dataloader(dataset, batch_size, num_workers=0):\n        return DataLoader(dataset, batch_size, num_workers=num_workers,\n            collate_fn=FracNetInferenceDataset._collate_fn)","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n\nclass UNet(nn.Module):\n    def __init__(self, in_channels, num_classes, first_out_channels=16):\n        super().__init__()\n        self.first = ConvBlock(in_channels, first_out_channels)\n        in_channels = first_out_channels\n        self.down1 = Down(in_channels, 2 * in_channels)\n        self.down2 = Down(2 * in_channels, 4 * in_channels)\n        self.down3 = Down(4 * in_channels, 8 * in_channels)\n        self.up1   = Up(8 * in_channels, 4 * in_channels)\n        self.up2   = Up(4 * in_channels, 2 * in_channels)\n        self.up3   = Up(2 * in_channels, in_channels)\n        self.final = nn.Conv3d(in_channels, num_classes, 1)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv3d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')\n            elif isinstance(m, nn.BatchNorm3d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def forward(self, x):\n         # If there's an extra dimension, squeeze it\n        if x.dim() == 6:\n            x = x.squeeze(2)  # Remove the extra dimension\n\n            print(\"Input shape after squeeze:\", x.shape)\n        \n        x1 = self.first(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x  = self.up1(x4, x3)\n        x  = self.up2(x, x2)\n        x  = self.up3(x, x1)\n        x  = self.final(x)\n        return x\n\n\nclass ConvBlock(nn.Sequential):\n    def __init__(self, in_channels, out_channels):\n        super().__init__(\n            nn.Conv3d(in_channels, out_channels, 3, padding=1, bias=False),\n            nn.BatchNorm3d(out_channels),\n            nn.LeakyReLU(inplace=True),\n            nn.Conv3d(out_channels, out_channels, 3, padding=1, bias=False),\n            nn.BatchNorm3d(out_channels),\n            nn.LeakyReLU(inplace=True)\n        )\n\n\nclass Down(nn.Sequential):\n    def __init__(self, in_channels, out_channels):\n        super().__init__(\n            nn.MaxPool3d(2),\n            ConvBlock(in_channels, out_channels)\n        )\n\n\nclass Up(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv1 = ConvBlock(in_channels, out_channels)\n        self.conv2 = nn.Sequential(\n            nn.ConvTranspose3d(in_channels, out_channels, 2, stride=2, bias=False),\n            nn.BatchNorm3d(out_channels),\n            nn.LeakyReLU(inplace=True)\n        )\n\n    def forward(self, x, y):\n        \n        x = self.conv2(x)\n        x = self.conv1(torch.cat([y, x], dim=1))\n        return x","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfrom functools import reduce\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\n__all__ = ['MixLoss', 'DiceLoss', 'GHMCLoss', 'FocalLoss']\n\n\nclass MixLoss(nn.Module):\n    def __init__(self, *args):\n        super().__init__()\n        self.args = args\n\n    def forward(self, x, y):\n        lf, lfw = [], []\n        for i, v in enumerate(self.args):\n            if i % 2 == 0:\n                lf.append(v)\n            else:\n                lfw.append(v)\n        mx = sum([w * l(x, y) for l, w in zip(lf, lfw)])\n        return mx\n\n\nclass DiceLoss(nn.Module):\n    def __init__(self, image=False):\n        super().__init__()\n        self.image = image\n\n    def forward(self, x, y):\n        x = x.sigmoid()\n        i, u = [t.flatten(1).sum(1) if self.image else t.sum() for t in [x * y, x + y]]\n\n        dc = (2 * i + 1) / (u + 1)\n        dc = 1 - dc.mean()\n        return dc\n\n\nclass GHMCLoss(nn.Module):\n    def __init__(self, mmt=0, bins=10):\n        super().__init__()\n        self.mmt = mmt\n        self.bins = bins\n        self.edges = [x / bins for x in range(bins + 1)]\n        self.edges[-1] += 1e-6\n\n        if mmt > 0:\n            self.acc_sum = [0] * bins\n\n    def forward(self, x, y):\n        w = torch.zeros_like(x)\n        g = torch.abs(x.detach().sigmoid() - y)\n\n        n = 0\n        t = reduce(lambda x, y: x * y, w.shape)\n        for i in range(self.bins):\n            ix = (g >= self.edges[i]) & (g < self.edges[i + 1]); nb = ix.sum()\n            if nb > 0:\n                if self.mmt > 0:\n                    self.acc_sum[i] = self.mmt * self.acc_sum[i] + (1 - self.mmt) * nb\n                    w[ix] = t / self.acc_sum[i]\n                else:\n                    w[ix] = t / nb\n                n += 1\n        if n > 0:\n            w = w / n\n\n        gc = F.binary_cross_entropy_with_logits(x, y, w, reduction='sum') / t\n        return gc\n\n\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=1, gamma=2):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n\n    def forward(self, x, y):\n        ce = F.binary_cross_entropy_with_logits(x, y)\n        fc = self.alpha * (1 - torch.exp(-ce)) ** self.gamma * ce\n        return fc","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef dice(x, y, image=False):\n    x = x.sigmoid()\n    i, u = [t.flatten(1).sum(1) if image else t.sum() for t in [x * y, x + y]]\n    dc = ((2 * i + 1) / (u + 1)).mean()\n    return dc\n\n\ndef recall(x, y, thresh=0.1):\n    x = x.sigmoid()\n    tp = (((x * y) > thresh).flatten(1).sum(1) > 0).sum()\n    rc = tp / (((y > 0).flatten(1).sum(1) > 0).sum() + 1e-8)\n    return rc\n\n\ndef accuracy(x, y, thresh=0.5):\n    x = x.sigmoid()\n    ac = ((x > thresh) == (y > 0)).float().mean()\n    return ac\n\n\ndef precision(x, y, thresh=0.1):\n    x = x.sigmoid()\n    tp = (((x * y) > thresh).flatten(1).sum(1) > 0).sum()\n    pc = tp / (((x > thresh).flatten(1).sum(1) > 0).sum() + 1e-8)\n    return pc\n\n\ndef fbeta_score(x, y, beta=1, **kwargs):\n    rc = recall(x, y, **kwargs)\n    pc = precision(x, y, **kwargs)\n    fs = (1 + beta ** 2) * pc * rc / (beta ** 2 * pc + rc + 1e-8)\n    return fs","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from functools import partial\nfrom fastai.callback.tensorboard import TensorBoardCallback\nfrom fastai.vision.all import *\nimport torch\nimport torch.nn.functional as F\nfrom torchmetrics import Recall, Precision, Dice, FBetaScore\nfrom torch import nn\n\nclass TransformCallback(Callback):\n    def before_batch(self):\n        if isinstance(self.learn.xb, tuple):\n            x = self.learn.xb[0]\n        else:\n            x = self.learn.xb\n            \n        if isinstance(self.learn.yb, tuple):\n            y = self.learn.yb[0]\n        else:\n            y = self.learn.yb\n        \n        # Handle input shape: [B, 4, 1, 64, 64, 64]\n        x = x.squeeze(2)  # Remove singleton dimension\n        \n        # Handle target shape: [B, 4, 64, 64, 64]\n        # Assuming this is a one-hot encoded target, convert to class indices\n        y = y.argmax(dim=1)\n        \n        self.learn.xb = (x,)\n        self.learn.yb = (y,)\n    \n    def after_pred(self):\n        pred = self.learn.pred[0] if isinstance(self.learn.pred, tuple) else self.learn.pred\n        target = self.learn.yb[0] if isinstance(self.learn.yb, tuple) else self.learn.yb\n        \n        self.learn.pred = pred\n        self.learn.yb = (target,)\n\ndef dice_score(input, target, epsilon=1e-6):\n    # input shape: [B, C, H, W, D] - model output (5 classes)\n    # target shape: [B, H, W, D] - class indices\n    probs = F.softmax(input, dim=1)\n    pred_classes = probs.argmax(dim=1)\n    \n    # Compute dice score\n    intersection = (pred_classes == target).float().sum()\n    dice = (2. * intersection + epsilon) / (pred_classes.numel() + target.numel() + epsilon)\n    \n    return dice\n\ndef multi_class_recall(input, target, num_classes=5):\n    # input shape: [B, C, H, W, D] - model output (5 classes)\n    # target shape: [B, H, W, D] - class indices\n    probs = F.softmax(input, dim=1)\n    pred_classes = probs.argmax(dim=1)\n    \n    # Initialize recall for each class\n    recalls = []\n    for cls in range(num_classes):\n        # Create binary masks for the current class\n        pred_mask = (pred_classes == cls).float()\n        target_mask = (target == cls).float()\n        \n        # Compute recall for the current class\n        true_positives = (pred_mask * target_mask).sum()\n        actual_positives = target_mask.sum()\n        \n        # Avoid division by zero\n        recall = true_positives / (actual_positives + 1e-6)\n        recalls.append(recall)\n    \n    # Return mean recall across classes\n    return torch.tensor(recalls).mean()\n\ndef multi_class_precision(input, target, num_classes=5):\n    # input shape: [B, C, H, W, D] - model output (5 classes)\n    # target shape: [B, H, W, D] - class indices\n    probs = F.softmax(input, dim=1)\n    pred_classes = probs.argmax(dim=1)\n    \n    # Initialize precision for each class\n    precisions = []\n    for cls in range(num_classes):\n        # Create binary masks for the current class\n        pred_mask = (pred_classes == cls).float()\n        target_mask = (target == cls).float()\n        \n        # Compute precision for the current class\n        true_positives = (pred_mask * target_mask).sum()\n        predicted_positives = pred_mask.sum()\n        \n        # Avoid division by zero\n        precision = true_positives / (predicted_positives + 1e-6)\n        precisions.append(precision)\n    \n    # Return mean precision across classes\n    return torch.tensor(precisions).mean()\n\ndef multi_class_fbeta_score(input, target, beta=1, num_classes=5):\n    # input shape: [B, C, H, W, D] - model output (5 classes)\n    # target shape: [B, H, W, D] - class indices\n    probs = F.softmax(input, dim=1)\n    pred_classes = probs.argmax(dim=1)\n    \n    # Initialize F-Beta scores for each class\n    fbeta_scores = []\n    for cls in range(num_classes):\n        # Create binary masks for the current class\n        pred_mask = (pred_classes == cls).float()\n        target_mask = (target == cls).float()\n        \n        # Compute true positives, false positives, and false negatives\n        true_positives = (pred_mask * target_mask).sum()\n        false_positives = ((pred_mask > 0) * (target_mask == 0)).sum()\n        false_negatives = ((pred_mask == 0) * (target_mask > 0)).sum()\n        \n        # Compute precision and recall\n        precision = true_positives / (true_positives + false_positives + 1e-6)\n        recall = true_positives / (true_positives + false_negatives + 1e-6)\n        \n        # Compute F-Beta score\n        # F-Beta = (1 + beta^2) * (precision * recall) / ((beta^2 * precision) + recall)\n        beta_sq = beta ** 2\n        fbeta = ((1 + beta_sq) * precision * recall) / ((beta_sq * precision) + recall + 1e-6)\n        \n        fbeta_scores.append(fbeta)\n    \n    # Return mean F-Beta score across classes\n    return torch.tensor(fbeta_scores).mean()\n\nclass CombinedLoss(nn.Module):\n    def __init__(self, weights=[0.5, 0.5]):\n        super().__init__()\n        self.weights = weights\n        self.ce = nn.CrossEntropyLoss()\n    \n    def forward(self, input, target):\n        # input: [B, C, H, W, D] - 5 classes\n        # target: [B, H, W, D] - class indices\n        ce_loss = self.ce(input, target)\n        \n        # Dice Loss calculation\n        probs = F.softmax(input, dim=1)\n        pred_classes = probs.argmax(dim=1)\n        \n        # One-hot encode target\n        encoded_target = F.one_hot(target, num_classes=input.shape[1])\n        encoded_target = encoded_target.permute(0, 4, 1, 2, 3).float()\n        \n        intersection = (probs * encoded_target).sum(dim=(2, 3, 4))\n        union = probs.sum(dim=(2, 3, 4)) + encoded_target.sum(dim=(2, 3, 4))\n        \n        dice_loss = 1 - ((2. * intersection + 1e-6) / (union + 1e-6)).mean()\n        \n        return self.weights[0] * ce_loss + self.weights[1] * dice_loss\n\ndef main():\n    train_image_dir = \"/kaggle/input/ribfrac2/train_image\"\n    train_label_dir = \"/kaggle/input/ribfrac2/train_label\"\n    val_image_dir = \"/kaggle/input/ribfrac2/val_image\"\n    val_label_dir = \"/kaggle/input/ribfrac2/val_label\"\n    \n    batch_size = 2  # Match your actual batch size\n    num_workers = 4\n    \n    # Model with input channels matching your data\n    model = UNet(in_channels=4, num_classes=5, first_out_channels=64)\n    model = nn.DataParallel(model.cuda())\n    \n    # Transforms\n    transforms = [\n        Window(-200, 1000),\n        MinMaxNorm(-200, 1000)\n    ]\n    \n    # Datasets and DataLoaders\n    ds_train = FracNetTrainDataset(\n        train_image_dir, \n        train_label_dir,\n        transforms=transforms\n    )\n    \n    ds_val = FracNetTrainDataset(\n        val_image_dir, \n        val_label_dir,\n        transforms=transforms\n    )\n    \n    dl_train = FracNetTrainDataset.get_dataloader(\n        ds_train, \n        batch_size, \n        shuffle=True,\n        num_workers=num_workers\n    )\n    \n    dl_val = FracNetTrainDataset.get_dataloader(\n        ds_val, \n        batch_size, \n        shuffle=False,\n        num_workers=num_workers\n    )\n    \n    # Create DataLoaders\n    dls = DataLoaders(dl_train, dl_val, device=default_device())\n    \n    # Loss function\n    loss_func = CombinedLoss(weights=[0.5, 0.5])\n    \n    # Create learner with additional metrics\n    learn = Learner(\n        dls,\n        model,\n        loss_func=loss_func,\n        metrics=[\n            dice_score,               # Dice score metric \n            multi_class_recall,        # Recall metric\n            multi_class_precision,     # Precision metric\n            partial(multi_class_fbeta_score, beta=1),  # F1 Score \n            partial(multi_class_fbeta_score, beta=2)   # F2 Score\n        ],\n        opt_func=Adam\n    )\n    \n    # Add callbacks\n    learn.add_cb(TransformCallback())\n    learn.add_cb(SaveModelCallback(monitor='dice_score', comp=np.greater))\n    \n    # Train model\n    try:\n        learn.fit_one_cycle(\n            40,\n            1e-3,\n            cbs=[GradientClip(3.0)]\n        )\n    except Exception as e:\n        print(f\"Training error: {str(e)}\")\n        batch = next(iter(dls.train))\n        x, y = batch\n        print(f\"Input shape: {x.shape}, Target shape: {y.shape}\")\n        raise e\n\n    # Save final model\n    torch.save(model.module.state_dict(), \"final_model.pth\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\n\ndef generate_dataset_summary():\n    print(\"Variables\".ljust(30), \"Internal training set\".ljust(25), \n          \"Internal verification set\".ljust(25), \"External verification set\")\n    print(\"=\"*100)\n\n    # Randomly generating data for demonstration\n    num_patients = [random.randint(9000, 12000), random.randint(1500, 2000), random.randint(1500, 2000)]\n    num_positive = [random.randint(7000, 8000), random.randint(300, 500), random.randint(800, 1000)]\n    num_negative = [p - pos for p, pos in zip(num_patients, num_positive)]\n    \n    num_bone_kernels = [random.randint(2000, 3000), random.randint(800, 900), random.randint(500, 600)]\n    bone_percent = [f\"{(k / p) * 100:.1f}%\" for k, p in zip(num_bone_kernels, num_patients)]\n    num_standard_kernels = [p - k for p, k in zip(num_patients, num_bone_kernels)]\n    std_percent = [f\"{(k / p) * 100:.1f}%\" for k, p in zip(num_standard_kernels, num_patients)]\n\n    num_slices = [[random.randint(500, 800), random.randint(3000, 3500), random.randint(7000, 8000)] for _ in range(3)]\n    mean_age = [round(random.uniform(48, 54), 1) for _ in range(3)]\n    sex_ratios = [[random.randint(60, 65), 100 - random.randint(60, 65)] for _ in range(3)]\n    \n    num_fractures = [random.randint(35000, 40000), random.randint(2000, 2500), random.randint(4000, 5000)]\n    displaced = [random.randint(8000, 9000), random.randint(400, 500), random.randint(800, 1000)]\n    non_displaced = [random.randint(10000, 12000), random.randint(500, 600), random.randint(1300, 1500)]\n    buckle = [random.randint(6000, 7000), random.randint(300, 400), random.randint(1100, 1300)]\n    old_fractures = [random.randint(10000, 12000), random.randint(700, 900), random.randint(800, 1000)]\n\n    # Print data row by row\n    def format_row(label, data, suffix=\"\"):\n        return label.ljust(30) + \"\".join([str(x).ljust(25) + suffix for x in data])\n    \n    print(format_row(\"No. of patients\", num_patients))\n    print(format_row(\"No. of positive patients\", num_positive))\n    print(format_row(\"No. of negative patients\", num_negative))\n    print(format_row(\"No. of bone kernels\", [f\"{k} ({p})\" for k, p in zip(num_bone_kernels, bone_percent)]))\n    print(format_row(\"No. of standard kernels\", [f\"{k} ({p})\" for k, p in zip(num_standard_kernels, std_percent)]))\n    print(format_row(\"No. of slices (> 2 mm)\", [n[0] for n in num_slices]))\n    print(format_row(\"No. of slices (<= 2 mm, > 1 mm)\", [n[1] for n in num_slices]))\n    print(format_row(\"No. of slices (<= 1 mm)\", [n[2] for n in num_slices]))\n    print(format_row(\"Mean age (range)\", mean_age, \" years\"))\n    print(format_row(\"Sex (male : female)\", [f\"{r[0]}% : {r[1]}%\" for r in sex_ratios]))\n    print(format_row(\"No. of fractures\", num_fractures))\n    print(format_row(\"No. of displaced fractures\", displaced))\n    print(format_row(\"No. of non-displaced fractures\", non_displaced))\n    print(format_row(\"No. of buckle fractures\", buckle))\n    print(format_row(\"No. of old fractures\", old_fractures))\n\n# Run the script\ngenerate_dataset_summary()","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null}]}